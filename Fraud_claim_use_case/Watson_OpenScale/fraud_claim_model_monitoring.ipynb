{"cells":[{"metadata":{},"cell_type":"markdown","source":["# <img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"]},{"metadata":{"collapsed":true},"cell_type":"markdown","source":["# Monitor your ML Models using Watson OpenScale and WML on Cloud Pak for Data"]},{"metadata":{},"cell_type":"markdown","source":["## 1. Setup the Notebook Environment"]},{"metadata":{},"cell_type":"markdown","source":["## 1.1 Install the necessary packages"]},{"metadata":{},"cell_type":"markdown","source":["### Watson OpenScale Python SDK"]},{"metadata":{},"cell_type":"code","source":["!pip install ibm-ai-openscale"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Scikit-learn version 0.20\n"]},{"metadata":{},"cell_type":"code","source":["!pip install scikit-learn==0.20.3"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Watson Machine Learning Python SDK"]},{"metadata":{},"cell_type":"code","source":["!pip install --upgrade watson-machine-learning-client-V4==1.0.93 | tail -n 1"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Restart the Notebook after Installing the required packages. By clicking on `Kernel>Restart`"]},{"metadata":{},"cell_type":"markdown","source":["## 1.2 Import Packages"]},{"metadata":{},"cell_type":"code","source":["from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.pipeline import FeatureUnion\n","from sklearn import preprocessing\n","from sklearn import svm, metrics\n","from scipy import sparse\n","from watson_machine_learning_client import WatsonMachineLearningAPIClient\n","from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n","import json\n","import ibm_db\n","\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","\n","from ibm_ai_openscale import APIClient4ICP\n","from ibm_ai_openscale.engines import *\n","from ibm_ai_openscale.utils import *\n","from ibm_ai_openscale.supporting_classes import PayloadRecord, Feature\n","from ibm_ai_openscale.supporting_classes.enums import *"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 2. Configuration"]},{"metadata":{},"cell_type":"markdown","source":["### 2.1 Global Variables"]},{"metadata":{},"cell_type":"markdown","source":["**<font color='red'> UPDATE THE VARIABLE 'dep_name' TO THE NAME OF THE DEPLOYMENT SPACE CREATED PREVIOUSLY</font>**\n","\n","1. Right Click on the project name in the upper left section of the screen\n","2. Click on the tab where the project is opened\n","3. Click on Settings tab\n","4. Copy the `Associated deployment space` which we created in the previous lab tutorial for watson machine learnig\n","5. Paste the value in the `dep_name` variable"]},{"metadata":{},"cell_type":"markdown","source":["**<font color='red'> UPDATE THE VARIABLE 'MODEL_NAME' TO A UNIQUE NAME</font>**"]},{"metadata":{},"cell_type":"code","source":["MODEL_NAME=\"fraud_claim_classifier_srs\"\n","DEPLOYMENT_NAME=\"fraud_claim_monitoring_deployment_srs\"\n","# Ensure you create a an empty Schema and store the name in this variable\n","SCHEMA_NAME=\"INSURANCE\"\n","\n","# Enter the Deployment Space you have associated project with \n","dep_name=\"fraud_prediction_deployment_space_srs\""],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.2 Add Dataset\n","\n","Select the `Insert Pandas Dataframe` option, after selecting the below cell. Ensure the variable name is `df_data_1`"]},{"metadata":{},"cell_type":"code","source":["\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.3 Update your AIOS Credentials"]},{"metadata":{},"cell_type":"markdown","source":["**<font color='red'> Add your `username` and `password`</font>**"]},{"metadata":{},"cell_type":"code","source":["WOS_CREDENTIALS={\n","    \"url\" : os.environ['RUNTIME_ENV_APSX_URL'],\n","    \"username\":\"XXXXXXX\",\n","    \"password\":\"XXXXXX\"\n","}"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.4 Input your WML Credentials \n"]},{"metadata":{},"cell_type":"code","source":["import sys,os,os.path\n","\n","\n","# WML_CREDENTIALS = {\n","# \"token\": os.environ['USER_ACCESS_TOKEN'],\n","# \"instance_id\" : \"wml_local\",\n","# \"url\" : os.environ['RUNTIME_ENV_APSX_URL'],\n","# \"version\": \"3.0.0\"\n","# }\n","WML_CREDENTIALS = WOS_CREDENTIALS.copy()\n","WML_CREDENTIALS['instance_id']='openshift'\n","WML_CREDENTIALS['version']='3.0.0'"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.5 Add your Db credentials\n","\n","#### These Db credentials are needed ONLY if you have NOT configured your `OpenScale Datamart`."]},{"metadata":{},"cell_type":"code","source":["\n","# DATABASE_CREDENTIALS = {\n","#     \"hostname\": \"dashdb-txn-sbox-yp-dal09-11.services.dal.bluemix.net\",\n","#     \"username\": \"tzm22305\",\n","#     \"password\": \"s2knhr3znx-c5s03\",\n","#     \"port\": 50000,\n","#     \"db\": \"BLUDB\",\n","    \n","# }\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 3. Create the Fraud claims prediction Model using Scikit-Learn"]},{"metadata":{},"cell_type":"code","source":["required_columns = ['insured_sex', 'insured_occupation', 'insured_hobbies',\n","       'capital_gains', 'capital_loss', 'incident_type', 'collision_type', 'incident_severity',\n","       'authorities_contacted', 'incident_hour_of_the_day', 'number_of_vehicles_involved',\n","       'witnesses', 'total_claim_amount', 'fraud_reported', 'policy_annual_premium']\n","\n","df1 = df_data_1[required_columns]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["#### Checking for missing values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df1.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["#### This step is required if you have missing values in the `insured_hobbies` which I missed during the lab excercise. Otherwise you can skip this step"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df1['insured_hobbies'].fillna('cross-fit', inplace=True)\n","df1.isnull().sum()"]},{"metadata":{},"cell_type":"code","source":["categorical_features = []\n","for col in df1.columns:\n","    if col != 'fraud_reported':\n","      if df1[col].dtype == 'object':\n","        categorical_features.append(col)\n","\n","numeric_features = df1.select_dtypes(include=['int64', 'float64']).columns\n","# df2 = pd.get_dummies(df1, columns = columns_to_encode)\n","df2 = df1"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["'''Add a categorical transformer to your model pipeline. \n","    You will need to add a label encoder into the model pipeline before storing it into WML '''\n","\n","\n","numeric_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='median')),\n","    ('scaler', StandardScaler())])\n","categorical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_transformer, numeric_features),\n","        ('cat', categorical_transformer, categorical_features)])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["df2['fraud_reported'] = df2['fraud_reported'].str.replace('Y', '1')\n","df2['fraud_reported'] = df2['fraud_reported'].str.replace('N', '0')\n","df2['fraud_reported'] = df2['fraud_reported'].astype(int)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["features = []\n","for col in df2.columns:\n","  if col != 'fraud_reported':\n","    features.append(col)\n","\n","target = 'fraud_reported'\n","\n","X = df2[features]\n","y = df2[target]"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["from sklearn.svm import SVC\n","from sklearn.metrics  import accuracy_score, classification_report\n","\n","pipeline = Pipeline(steps=[\n","        ('preprocessor', preprocessor),\n","#         ('scale', StandardScaler()),\n","        ('clf', SVC(kernel = 'linear'))])\n","pipeline.fit(X_train, y_train)\n","\n","preds = pipeline.predict(X_test)\n","\n","print(accuracy_score(preds, y_test))\n","print(classification_report(y_test, preds))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 4. Create a new deployment"]},{"metadata":{},"cell_type":"code","source":["client = WatsonMachineLearningAPIClient(WML_CREDENTIALS)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["meta_props={\n"," client.repository.ModelMetaNames.NAME: MODEL_NAME,\n"," client.repository.ModelMetaNames.RUNTIME_UID: \"scikit-learn_0.20-py3.6\",\n"," client.repository.ModelMetaNames.TYPE: \"scikit-learn_0.20\",\n","}"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["\n","project_id = os.environ['PROJECT_ID']\n","client.set.default_project(project_id)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["def guid_from_space_name(client, space_name):\n","\n","    instance_details = client.service_instance.get_details()\n","\n","    space = client.spaces.get_details()\n","    res=[]\n","    for item in space['resources']: \n","        if item['entity'][\"name\"] == space_name:\n","            res=item['metadata']['guid']\n","\n","    return res"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["# Enter the name of your deployment space of the current project\n","\n","space_uid = guid_from_space_name(client, dep_name)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["space_uid"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["client.set.default_space(space_uid)\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Store, Deploy and Score your Custom WML Model"]},{"metadata":{},"cell_type":"code","source":["deploy_meta = {\n","     client.deployments.ConfigurationMetaNames.NAME: DEPLOYMENT_NAME,\n","     client.deployments.ConfigurationMetaNames.ONLINE: {}\n"," }"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["## Store the model on WML\n","published_model = client.repository.store_model(pipeline,\n","                                             meta_props=meta_props,\n","                                             training_data=X_train,\n","                                             training_target=y_train\n","                                                )\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["published_model_uid = client.repository.get_model_uid(published_model)"],"execution_count":null,"outputs":[]},{"metadata":{"scrolled":true},"cell_type":"code","source":["## Create a Deployment for your stored model\n","\n","created_deployment = client.deployments.create(published_model_uid, meta_props=deploy_meta)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["\n","scoring_endpoint = None\n","deployment_uid=created_deployment['metadata']['guid']"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 5. Setup your Watson Openscale Dashboard "]},{"metadata":{},"cell_type":"markdown","source":["### 5.1 Create the Watson Openscale Client"]},{"metadata":{},"cell_type":"code","source":["ai_client = APIClient4ICP(aios_credentials=WOS_CREDENTIALS)\n","ai_client.version"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 5.2 Setup the Datamart on AI OpenScale"]},{"metadata":{},"cell_type":"code","source":["try:\n","    data_mart_details = ai_client.data_mart.get_details()\n","    print('Using existing external datamart')\n","except:\n","    print('Setting up external datamart')\n","    ai_client.data_mart.setup(db_credentials=DATABASE_CREDENTIALS, schema=SCHEMA_NAME)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["data_mart_details = ai_client.data_mart.get_details()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["data_mart_details"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 5.3 Add your Machine Learning Provider\n","\n","If you have already bound the ML Provider to the Openscale instance, then just retrieve the binding_uid, by commenting first line and uncommenting the second line"]},{"metadata":{},"cell_type":"code","source":["WML_CREDENTIALS"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["**<font color='red'> Add your initials to the instance name like `WML instance - srs`</font>**"]},{"metadata":{},"cell_type":"code","source":["binding_uid = ai_client.data_mart.bindings.add('WML instance - srs', WatsonMachineLearningInstance4ICP(wml_credentials=WML_CREDENTIALS))\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ai_client.data_mart.bindings.list_assets()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 5.4 Perform Initial Scoring for your Model Deployment\n"]},{"metadata":{},"cell_type":"code","source":["score=X_test.tail(20)\n","score"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["scoring_data=list(list(x) for x in zip(*(score[x].values.tolist() for x in score.columns)))\n","scoring_data"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["fields=list(X_test.columns)\n","print(len(fields))\n","fields, scoring_data[0]"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["\n","job_payload = {\n","client.deployments.ScoringMetaNames.INPUT_DATA: [{\n"," 'values': scoring_data\n","}]\n","}\n","print(job_payload)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["scoring_response = client.deployments.score(deployment_uid, job_payload)\n","\n","print(scoring_response)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 5.5 Create a new Subscription "]},{"metadata":{},"cell_type":"code","source":["subscription = ai_client.data_mart.subscriptions.add(WatsonMachineLearningAsset(\n","    published_model_uid,\n","    problem_type=ProblemType.BINARY_CLASSIFICATION,\n","    input_data_type=InputDataType.STRUCTURED,\n","    label_column='fraud_reported',\n","    prediction_column='prediction',\n","    probability_column='prediction_probability',\n","    categorical_columns = categorical_features,\n","    feature_columns = list(X_train.columns.values),\n","#     feature_columns = list(numeric_features.values),\n","))"],"execution_count":null,"outputs":[]},{"metadata":{"scrolled":true},"cell_type":"code","source":["subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n","ai_client.data_mart.subscriptions.list()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 5.6 Perform Inital Payload Logging\n","Note: You may re-use this code snippet by modifying the request_data variable to perform payload logging after finishing the initial dashboard setup"]},{"metadata":{},"cell_type":"code","source":["fields=list(X_test.columns)\n","\n","request_data = {\n","    \"fields\": fields,\n","    \"values\": scoring_data\n","  }\n","request_data"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["**<font color='red'><< REPLACE subscription_uid BELOW with the uid for your subscription. For e.g.<br/>subscription_uid=\"644e4e6d-8a82-4f07-9489-381d44469a23\" >></font>**"]},{"metadata":{},"cell_type":"code","source":["## From the output of the above table choose your model name and copy the uid against it. Store the uid in the subscription_uid variable\n","\n","\n","subscription_uid=\"0ac145d5-f898-4e73-a5b5-a12294824099\"\n","from ibm_ai_openscale import APIClient4ICP\n","from ibm_ai_openscale.supporting_classes import PayloadRecord\n","\n","\n","subscription = ai_client.data_mart.subscriptions.get(subscription_uid=subscription_uid)\n","\n","\n","records = [PayloadRecord(request=request_data, response=scoring_response, response_time=18), \n","                PayloadRecord(request=request_data, response=scoring_response, response_time=12)]\n","\n","subscription.payload_logging.store(records=records)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 5.7 Setup Quality Monitoring\n","\n","```NOTE: If you are using the dataset provided in the workshop, leave the threshold monitors to these values. However, if you are using your own dataset, you can play around with the threshold value (value b/w 0 and 1) according to your requirement.```"]},{"metadata":{},"cell_type":"code","source":["time.sleep(5)\n","subscription.quality_monitoring.enable(threshold=0.90, min_records=5)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 5.8 Log Feedback Data to your Subscription"]},{"metadata":{},"cell_type":"code","source":["feedback_data_raw=pd.concat([X_test,y_test],axis=1)\n","feedback_data_raw"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["feedback_data=list(map(list, feedback_data_raw.tail(100).itertuples(index=False)))\n","feedback_data"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["# feedback_data=feedback_data_raw.tail(20).values.tolist()\n","# feedback_data"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["feedback_scoring={\n","    \"data\":feedback_data\n","}"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["subscription.feedback_logging.store(feedback_scoring['data'])\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["subscription.feedback_logging.show_table()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### Run an inital quality test"]},{"metadata":{},"cell_type":"code","source":["run_details = subscription.quality_monitoring.run(background_mode=False)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["subscription.quality_monitoring.show_table()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["%matplotlib inline\n","\n","quality_pd = subscription.quality_monitoring.get_table_content(format='pandas')\n","quality_pd.plot.barh(x='id', y='value');"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 5.9 Setup the Fairness Monitors\n","\n","The code below configures fairness monitoring for our model. It turns on monitoring for one feature, gender of the insured. In each case, we must specify:\n","  * Which model feature to monitor\n","  * One or more **majority** groups, which are values of that feature that we expect to receive a higher percentage of favorable outcomes\n","  * One or more **minority** groups, which are values of that feature that we expect to receive a higher percentage of unfavorable outcomes\n","  * The threshold at which we would like OpenScale to display an alert if the fairness measurement falls below (in this case, 95%)\n","\n","Additionally, we must specify which outcomes from the model are favourable outcomes, and which are unfavourable. We must also provide the number of records OpenScale will use to calculate the fairness score. In this case, OpenScale's fairness monitor will run hourly, but will not calculate a new fairness rating until at least 50 records have been added. Finally, to calculate fairness, OpenScale must perform some calculations on the training data, so we provide the dataframe containing the data."]},{"metadata":{},"cell_type":"code","source":["subscription.fairness_monitoring.enable(\n","            features=[\n","                Feature(\"insured_sex\", majority=['MALE'], minority=['FEMALE'], threshold=0.95),\n","            ],\n","            favourable_classes=[\"1\"],\n","            unfavourable_classes=[\"0\"],\n","            min_records=50,\n","            training_data=df_data_1\n","        )"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["score2=X_test.head(200)\n","\n","scoring_data2=list(list(x) for x in zip(*(score2[x].values.tolist() for x in score2.columns)))\n","\n","fields2=list(X_test.columns)\n","\n","job_payload2 = {\n","client.deployments.ScoringMetaNames.INPUT_DATA: [{\n"," 'values': scoring_data2\n","}]\n","}\n","\n","scoring_response2 = client.deployments.score(deployment_uid, job_payload2)\n","\n","\n","request_data2 = {\n","    \"fields\": fields,\n","    \"values\": scoring_data2\n","  }\n","\n","records2 = [PayloadRecord(request=request_data2, response=scoring_response2, response_time=18), \n","                PayloadRecord(request=request_data2, response=scoring_response2, response_time=12)]\n","\n","subscription.payload_logging.store(records=records2)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["time.sleep(200)\n","\n","run_details = subscription.fairness_monitoring.run(background_mode=False)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["time.sleep(5)\n","\n","subscription.fairness_monitoring.show_table()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 6.0 Custom monitors and metrics\n"]},{"metadata":{},"cell_type":"markdown","source":["### 6.1 Register custom monitor"]},{"metadata":{},"cell_type":"code","source":["def get_definition(monitor_name):\n","    monitors_definitions = ai_client.data_mart.monitors.get_details()['monitor_definitions']\n","    \n","    for definition in monitors_definitions:\n","        if monitor_name == definition['entity']['name']:\n","            return definition\n","    \n","    return None"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Change `monitor_name` to something unique."]},{"metadata":{},"cell_type":"code","source":["from ibm_ai_openscale.supporting_classes import Metric, Tag\n","\n","monitor_name = 'custom_monitor_shivam'\n","metrics = [Metric(name='sensitivity', lower_limit_default=0.8), Metric(name='specificity', lower_limit_default=0.75)]\n","tags = [Tag(name='region', description='customer geographical region')]\n","\n","existing_definition = get_definition(monitor_name)\n","\n","if existing_definition is None:\n","    my_monitor = ai_client.data_mart.monitors.add(name=monitor_name, metrics=metrics, tags=tags)\n","else:\n","    my_monitor = existing_definition"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 6.1.1 Get monitors uids and details"]},{"metadata":{},"cell_type":"code","source":["monitor_uid = my_monitor['metadata']['guid']\n","\n","print(monitor_uid)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["my_monitor = ai_client.data_mart.monitors.get_details(monitor_uid=monitor_uid)\n","print('monitor definition details', my_monitor)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 6.2 Enable custom monitor for subscription"]},{"metadata":{},"cell_type":"code","source":["from ibm_ai_openscale.supporting_classes import Threshold\n","\n","thresholds = [Threshold(metric_uid='sensitivity', lower_limit=0.9)]\n","subscription.monitoring.enable(monitor_uid=monitor_uid, thresholds=thresholds)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 6.2.1 Get monitor configuration details"]},{"metadata":{},"cell_type":"code","source":["subscription.monitoring.get_details(monitor_uid=monitor_uid)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 6.3 Storing custom metrics"]},{"metadata":{},"cell_type":"code","source":["metrics = {\"specificity\": 0.78, \"sensitivity\": 0.67, \"region\": \"us-south\"}\n","\n","subscription.monitoring.store_metrics(monitor_uid=monitor_uid, metrics=metrics)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 6.3.1 List and get custom metrics"]},{"metadata":{},"cell_type":"code","source":["subscription.monitoring.show_table(monitor_uid=monitor_uid)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["custom_metrics = subscription.monitoring.get_metrics(monitor_uid=monitor_uid, deployment_uid='credit')\n","custom_metrics"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["custom_metrics_pandas = subscription.monitoring.get_table_content(monitor_uid=monitor_uid)\n","\n","%matplotlib inline\n","custom_metrics_pandas.plot.barh(x='id', y='value');"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 7.0 Payload analytics\n"]},{"metadata":{},"cell_type":"markdown","source":["### 7.1 Run data distributions calculation"]},{"metadata":{},"cell_type":"code","source":["from datetime import datetime\n","\n","start_date = \"2018-01-01T00:00:00.00Z\"\n","end_date = datetime.utcnow().isoformat() + \"Z\"\n","\n","sex_distribution = subscription.payload_logging.data_distribution.run(\n","            start_date=start_date,\n","            end_date=end_date,\n","            group=['prediction', 'insured_sex'],\n","            agg=['count'])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 7.2 Get data distributions as pandas dataframe\n"]},{"metadata":{},"cell_type":"code","source":["sex_distribution_run_uid = sex_distribution['id']\n","distributions_pd = subscription.payload_logging.data_distribution.get_run_result(run_id=sex_distribution_run_uid, format='pandas')\n","distributions_pd"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["subscription.payload_logging.data_distribution.show_chart(sex_distribution_run_uid);"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 8. Identify transactions for Explainability"]},{"metadata":{},"cell_type":"code","source":["from ibm_ai_openscale.supporting_classes import *\n","subscription.explainability.enable(training_data=df_data_1)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["payload_data = subscription.payload_logging.get_table_content(limit=60)\n","payload_data.filter(items=['scoring_id', 'predictedLabel', 'probability'])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Add some more Payload (Optional for populating your dashboard)\n","\n","If you wish to add some Payload Data. Take different sections of your test dataset and send to OpenScale as shown below-"]},{"metadata":{},"cell_type":"code","source":["score100=X_test.head(100)\n","score100"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["scoring_data100=list(list(x) for x in zip(*(score100[x].values.tolist() for x in score100.columns)))\n","scoring_data100"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["fields=list(X_test.columns)\n","print(len(fields))\n","fields, scoring_data100[0]"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["request_data100 = {\n","    \"fields\": fields,\n","    \"values\": scoring_data100\n","  }\n","request_data100"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["records100 = [PayloadRecord(request=request_data100, response=scoring_response, response_time=18), \n","                PayloadRecord(request=request_data100, response=scoring_response, response_time=12)]\n","\n","subscription.payload_logging.store(records=records100)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":[],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python37364bitc53e408c220b435f82f7ec57dd724fbe","display_name":"Python 3.7.3 64-bit","language":"python"},"language_info":{"name":"python","version":"3.7.3-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}